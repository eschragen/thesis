####LIBRARIES####
library(tidyverse)
library(jtools)
library(Rcpp)
library(mctest)
library(ggplot2)
library(stats)
options(scipen=999)
####PREPARE DATA####
data = read_csv("C:/Users/eva_s/OneDrive/MASTER/5. Semester_THESIS/Data Analytics/DATA/df_select.csv")
df = data %>% select(-c(X1,date,tweet,username,employees,total_assets))
#compute new output variable (* 100)
df = df %>% mutate(vice_sum_100 = 100*vice_sum) %>% drop_na(vice_sum, followers_count)
#create factors
df$green_ad = as.factor(df$green_ad)
df$max_morality = as.factor(df$max_morality)
df$topic = as.factor(df$topic)
df$industry_brown = as.factor(df$industry_brown)
#exclude outliers of metric variables
df = df %>% filter(following_count <= quantile(following_count, 0.95, na.rm = TRUE),
followers_count <= quantile(followers_count, 0.95, na.rm = TRUE),
vice_virality <= quantile(vice_virality, 0.95, na.rm = TRUE))
#normalize metric features
df_numeric = df %>% select(-c(id, company, sic, industry1,industry2,industry_brown, revenues_class,
green_ad, max_morality, topic, year,
fairness_foundation))
min_max = function(x) {(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))}
df_numeric_norm = as.data.frame(lapply(df_numeric, min_max))
colnames(df_numeric_norm) = paste(colnames(df_numeric_norm),"norm",sep="_")
df_new = cbind(df, df_numeric_norm)
#rename variables
df_new = df_new %>% rename("moral_outrage" = "vice_sum_100", "negativeWOM_volume" = "vice_virality_norm",
"followers" = "followers_count_norm", "following" = "following_count_norm")
####CREATE MODEL####
fit = lm(moral_outrage ~
industry_brown  + industry_brown*green_ad +
negativeWOM_volume +
relevel(max_morality, ref = "intensity_fairness")+
relevel(topic, ref = "4") +
followers + following,
data = df_new)
#extract top 10 highest cooks distance
top10cooks = df_new[c(which(rownames(df_new) %in% names(sort(cooks.distance(fit), decreasing = T)[1:10]))),]
#combine in one df & exclude from original df (df_new)
top5outlier = rbind(top10cooks) # top5residuals,,top5influence,top5standresiduals)
ids_notoutlier = as.data.frame(df_new$id[!df_new$id %in% top5outlier$id])
colnames(ids_notoutlier) = "id"
df_new2 = ids_notoutlier %>% left_join(df_new, by = "id")
fit2 = lm(moral_outrage ~
industry_brown  + industry_brown*green_ad +
negativeWOM_volume +
following + followers +
relevel(topic, ref = "4") +
relevel(max_morality, ref = "intensity_fairness"),
data = df_new2)
#Linearity between predictors and outcome variable (Residuals vs Fitted plot)
##Check: No fitted pattern (Red line approx. horizontal at Zero)
plot(fit2,1, sub.caption = NA , cex.lab = 1.5, cex.axis = 1.5, cex.main = 2.5, lwd = 3)
sresid = studres(fit2)
hist(sresid, freq=FALSE,main="Distribution of Studentized Residuals", xlab = "Studentized Residuals")
sresid = studres(fit2)
# #Generate histogram of residual distribution
library(MASS)
sresid = studres(fit2)
hist(sresid, freq=FALSE,main="Distribution of Studentized Residuals", xlab = "Studentized Residuals")
xfit=seq(min(sresid),max(sresid),length=40)
yfit=dnorm(xfit)
lines(xfit, yfit)
sresid = MASS::studres(fit2)
plot(fit2, 2)
plot(fit2, 2,sub.caption = NA , cex.lab = 1.5, cex.axis = 1.5, cex.main = 2.5, lwd = 3)
####3. HOMOSCEDASTICITY####
#Nonconstant Error Variance (Scale/Spread-location plot)
# #Horizontal line with equally spread points = residuals spread equally along ranges of predictors = Homogeneity of Variance
plot(fit2,3, sub.caption = NA , cex.lab = 1.5, cex.axis = 1.5, cex.main = 2.5, lwd = 3)
#extract top 10 highest cooks distance
top10cooks_ikea = ikea[c(which(rownames(ikea) %in% names(sort(cooks.distance(fit_ikea), decreasing = T)[1:10]))),]
####LIBRARIES####
library(tidyverse)
library(jtools)
library(Rcpp)
library(mctest)
library(ggplot2)
library(stats)
options(scipen=999)
####PREPARE DATA####
data = read_csv("C:/Users/eva_s/OneDrive/MASTER/5. Semester_THESIS/Data Analytics/DATA/df_select.csv")
df = data %>% select(-c(X1,date,tweet,username,employees,total_assets))
#compute new output variable (* 100)
df = df %>% mutate(vice_sum_100 = 100*vice_sum) %>% drop_na(vice_sum, followers_count)
#create factors
df$green_ad = as.factor(df$green_ad)
df$max_morality = as.factor(df$max_morality)
df$topic = as.factor(df$topic)
df$industry_brown = as.factor(df$industry_brown)
#exclude outliers of metric variables
df = df %>% filter(following_count <= quantile(following_count, 0.95, na.rm = TRUE),
followers_count <= quantile(followers_count, 0.95, na.rm = TRUE),
vice_virality <= quantile(vice_virality, 0.95, na.rm = TRUE))
#normalize metric features
df_numeric = df %>% select(-c(id, company, sic, industry1,industry2,industry_brown, revenues_class,
green_ad, max_morality, topic, year,
fairness_foundation))
min_max = function(x) {(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))}
df_numeric_norm = as.data.frame(lapply(df_numeric, min_max))
colnames(df_numeric_norm) = paste(colnames(df_numeric_norm),"norm",sep="_")
df_new = cbind(df, df_numeric_norm)
#rename variables
df_new = df_new %>% rename("moral_outrage" = "vice_sum_100", "negativeWOM_volume" = "vice_virality_norm",
"followers" = "followers_count_norm", "following" = "following_count_norm")
####CREATE MODELS####
cocacola = df_new %>% filter(company == "cocacola")
fit_cocacola = lm(moral_outrage ~
negativeWOM_volume +
relevel(max_morality, ref = "intensity_fairness")+
relevel(topic, ref = "4") +
followers + following,
data = cocacola)
vw = df_new %>% filter(company == "vw")
fit_vw= lm(moral_outrage ~
negativeWOM_volume +
relevel(max_morality, ref = "intensity_fairness")+
relevel(topic, ref = "4") +
followers + following,
data = vw)
exxonmobil = df_new %>% filter(company == "exxonmobil")
fit_exxonmobil= lm(moral_outrage ~
negativeWOM_volume +
relevel(max_morality, ref = "intensity_fairness")+
relevel(topic, ref = "4") +
followers + following,
data = exxonmobil)
shell = df_new %>% filter(company == "shell")
fit_shell= lm(moral_outrage ~
negativeWOM_volume +
relevel(max_morality, ref = "intensity_fairness")+
relevel(topic, ref = "4") +
followers + following,
data = shell)
nestle = df_new %>% filter(company == "nestle")
fit_nestle= lm(moral_outrage ~
negativeWOM_volume +
relevel(max_morality, ref = "intensity_fairness")+
relevel(topic, ref = "4") +
followers + following,
data = nestle)
hm = df_new %>% filter(company == "hm")
fit_hm= lm(moral_outrage ~
negativeWOM_volume +
relevel(max_morality, ref = "intensity_fairness")+
relevel(topic, ref = "4") +
followers + following,
data = hm)
unilever = df_new %>% filter(company == "unilever")
fit_unilever= lm(moral_outrage ~
negativeWOM_volume +
relevel(max_morality, ref = "intensity_fairness")+
relevel(topic, ref = "4") +
followers + following,
data = unilever)
ikea = df_new %>% filter(company == "ikea")
fit_ikea= lm(moral_outrage ~
negativeWOM_volume +
relevel(max_morality, ref = "intensity_fairness")+
relevel(topic, ref = "4") +
followers + following,
data=ikea)
#compute new output variable (* 100)
df = df %>% mutate(vice_sum_100 = 100*vice_sum) %>% drop_na(vice_sum, followers_count)
####LIBRARIES####
library(tidyverse)
library(jtools)
library(Rcpp)
library(mctest)
library(ggplot2)
library(stats)
options(scipen=999)
#compute new output variable (* 100)
df = df %>% mutate(vice_sum_100 = 100*vice_sum) %>% drop_na(vice_sum, followers_count)
